//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34431801
// Cuda compilation tools, release 12.6, V12.6.20
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_52
.address_size 64

	// .globl	_Z26evaluate_polynomial_kernelPfjfS_

.visible .entry _Z26evaluate_polynomial_kernelPfjfS_(
	.param .u64 _Z26evaluate_polynomial_kernelPfjfS__param_0,
	.param .u32 _Z26evaluate_polynomial_kernelPfjfS__param_1,
	.param .f32 _Z26evaluate_polynomial_kernelPfjfS__param_2,
	.param .u64 _Z26evaluate_polynomial_kernelPfjfS__param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<11>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd3, [_Z26evaluate_polynomial_kernelPfjfS__param_0];
	ld.param.u32 	%r3, [_Z26evaluate_polynomial_kernelPfjfS__param_1];
	ld.param.f32 	%f5, [_Z26evaluate_polynomial_kernelPfjfS__param_2];
	ld.param.u64 	%rd4, [_Z26evaluate_polynomial_kernelPfjfS__param_3];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mov.f32 	%f10, 0f00000000;
	mov.f32 	%f9, 0f3F800000;
	mov.u32 	%r5, 0;

$L__BB0_1:
	mul.wide.u32 	%rd5, %r5, 4;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f32 	%f8, [%rd6];
	fma.rn.f32 	%f10, %f9, %f8, %f10;
	mul.f32 	%f9, %f9, %f5;
	add.s32 	%r5, %r5, 1;
	setp.le.u32 	%p1, %r5, %r3;
	@%p1 bra 	$L__BB0_1;

	st.global.f32 	[%rd1], %f10;
	ret;

}
	// .globl	_Z36calculate_quotient_polynomial_kernelPfjffS_
.visible .entry _Z36calculate_quotient_polynomial_kernelPfjffS_(
	.param .u64 _Z36calculate_quotient_polynomial_kernelPfjffS__param_0,
	.param .u32 _Z36calculate_quotient_polynomial_kernelPfjffS__param_1,
	.param .f32 _Z36calculate_quotient_polynomial_kernelPfjffS__param_2,
	.param .f32 _Z36calculate_quotient_polynomial_kernelPfjffS__param_3,
	.param .u64 _Z36calculate_quotient_polynomial_kernelPfjffS__param_4
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<28>;
	.reg .b32 	%r<27>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd2, [_Z36calculate_quotient_polynomial_kernelPfjffS__param_0];
	ld.param.u32 	%r13, [_Z36calculate_quotient_polynomial_kernelPfjffS__param_1];
	ld.param.f32 	%f7, [_Z36calculate_quotient_polynomial_kernelPfjffS__param_2];
	ld.param.f32 	%f8, [_Z36calculate_quotient_polynomial_kernelPfjffS__param_3];
	ld.param.u64 	%rd3, [_Z36calculate_quotient_polynomial_kernelPfjffS__param_4];
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mul.lo.s32 	%r1, %r15, %r14;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r25, %r1, %r2;
	setp.ge.u32 	%p1, %r25, %r13;
	@%p1 bra 	$L__BB1_5;

	cvta.to.global.u64 	%rd4, %rd2;
	mul.wide.u32 	%rd5, %r25, 4;
	add.s64 	%rd6, %rd4, %rd5;
	setp.eq.s32 	%p2, %r25, 0;
	selp.f32 	%f9, %f7, 0f00000000, %p2;
	ld.global.f32 	%f10, [%rd6];
	sub.f32 	%f26, %f10, %f9;
	sub.s32 	%r16, %r13, %r1;
	sub.s32 	%r17, %r16, %r2;
	not.b32 	%r18, %r1;
	add.s32 	%r19, %r18, %r13;
	sub.s32 	%r4, %r19, %r2;
	and.b32  	%r24, %r17, 3;
	setp.eq.s32 	%p3, %r24, 0;
	@%p3 bra 	$L__BB1_3;

$L__BB1_2:
	.pragma "nounroll";
	mul.wide.u32 	%rd7, %r25, 4;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.f32 	%f11, [%rd8];
	add.f32 	%f12, %f26, %f11;
	st.global.f32 	[%rd8], %f12;
	mul.f32 	%f13, %f26, %f8;
	neg.f32 	%f26, %f13;
	add.s32 	%r25, %r25, 1;
	add.s32 	%r24, %r24, -1;
	setp.ne.s32 	%p4, %r24, 0;
	@%p4 bra 	$L__BB1_2;

$L__BB1_3:
	setp.lt.u32 	%p5, %r4, 3;
	@%p5 bra 	$L__BB1_5;

$L__BB1_4:
	mul.wide.u32 	%rd9, %r25, 4;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.f32 	%f14, [%rd10];
	add.f32 	%f15, %f26, %f14;
	st.global.f32 	[%rd10], %f15;
	add.s32 	%r20, %r25, 1;
	mul.wide.u32 	%rd11, %r20, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.f32 	%f16, [%rd12];
	mul.f32 	%f17, %f26, %f8;
	sub.f32 	%f18, %f16, %f17;
	st.global.f32 	[%rd12], %f18;
	mul.f32 	%f19, %f17, %f8;
	add.s32 	%r21, %r25, 2;
	mul.wide.u32 	%rd13, %r21, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f20, [%rd14];
	add.f32 	%f21, %f19, %f20;
	st.global.f32 	[%rd14], %f21;
	mul.f32 	%f22, %f19, %f8;
	add.s32 	%r22, %r25, 3;
	mul.wide.u32 	%rd15, %r22, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.f32 	%f23, [%rd16];
	sub.f32 	%f24, %f23, %f22;
	st.global.f32 	[%rd16], %f24;
	mul.f32 	%f26, %f22, %f8;
	add.s32 	%r25, %r25, 4;
	setp.lt.u32 	%p6, %r25, %r13;
	@%p6 bra 	$L__BB1_4;

$L__BB1_5:
	ret;

}
	// .globl	_Z18perform_msm_kernelPfS_jS_
.visible .entry _Z18perform_msm_kernelPfS_jS_(
	.param .u64 _Z18perform_msm_kernelPfS_jS__param_0,
	.param .u64 _Z18perform_msm_kernelPfS_jS__param_1,
	.param .u32 _Z18perform_msm_kernelPfS_jS__param_2,
	.param .u64 _Z18perform_msm_kernelPfS_jS__param_3
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<30>;
	.reg .b32 	%r<34>;
	.reg .b64 	%rd<26>;


	ld.param.u64 	%rd7, [_Z18perform_msm_kernelPfS_jS__param_0];
	ld.param.u64 	%rd8, [_Z18perform_msm_kernelPfS_jS__param_1];
	ld.param.u32 	%r17, [_Z18perform_msm_kernelPfS_jS__param_2];
	ld.param.u64 	%rd6, [_Z18perform_msm_kernelPfS_jS__param_3];
	cvta.to.global.u64 	%rd1, %rd8;
	cvta.to.global.u64 	%rd2, %rd7;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mov.u32 	%r20, %tid.x;
	mad.lo.s32 	%r1, %r19, %r18, %r20;
	setp.gt.u32 	%p1, %r1, 1;
	@%p1 bra 	$L__BB2_9;

	setp.eq.s32 	%p2, %r17, 0;
	mov.f32 	%f29, 0f00000000;
	@%p2 bra 	$L__BB2_8;

	add.s32 	%r22, %r17, -1;
	and.b32  	%r33, %r17, 3;
	setp.lt.u32 	%p3, %r22, 3;
	mov.f32 	%f29, 0f00000000;
	mov.u32 	%r31, 0;
	@%p3 bra 	$L__BB2_5;

	add.s32 	%r29, %r1, 6;
	sub.s32 	%r4, %r33, %r17;
	mov.f32 	%f29, 0f00000000;
	mov.u32 	%r31, 0;
	mov.u32 	%r28, %r1;

$L__BB2_4:
	mul.wide.u32 	%rd9, %r28, 4;
	add.s64 	%rd10, %rd2, %rd9;
	mul.wide.u32 	%rd11, %r31, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.f32 	%f12, [%rd12];
	ld.global.f32 	%f13, [%rd10];
	fma.rn.f32 	%f14, %f13, %f12, %f29;
	add.s32 	%r24, %r28, 2;
	mul.wide.u32 	%rd13, %r24, 4;
	add.s64 	%rd14, %rd2, %rd13;
	ld.global.f32 	%f15, [%rd12+4];
	ld.global.f32 	%f16, [%rd14];
	fma.rn.f32 	%f17, %f16, %f15, %f14;
	add.s32 	%r25, %r29, -2;
	mul.wide.u32 	%rd15, %r25, 4;
	add.s64 	%rd16, %rd2, %rd15;
	ld.global.f32 	%f18, [%rd12+8];
	ld.global.f32 	%f19, [%rd16];
	fma.rn.f32 	%f20, %f19, %f18, %f17;
	mul.wide.u32 	%rd17, %r29, 4;
	add.s64 	%rd18, %rd2, %rd17;
	ld.global.f32 	%f21, [%rd12+12];
	ld.global.f32 	%f22, [%rd18];
	fma.rn.f32 	%f29, %f22, %f21, %f20;
	add.s32 	%r29, %r29, 8;
	add.s32 	%r28, %r28, 8;
	add.s32 	%r31, %r31, 4;
	add.s32 	%r26, %r4, %r31;
	setp.ne.s32 	%p4, %r26, 0;
	@%p4 bra 	$L__BB2_4;

$L__BB2_5:
	setp.eq.s32 	%p5, %r33, 0;
	@%p5 bra 	$L__BB2_8;

	mul.wide.u32 	%rd19, %r31, 4;
	add.s64 	%rd25, %rd1, %rd19;
	shl.b32 	%r27, %r31, 1;
	add.s32 	%r32, %r1, %r27;

$L__BB2_7:
	.pragma "nounroll";
	mul.wide.u32 	%rd20, %r32, 4;
	add.s64 	%rd21, %rd2, %rd20;
	ld.global.f32 	%f23, [%rd25];
	ld.global.f32 	%f24, [%rd21];
	fma.rn.f32 	%f29, %f24, %f23, %f29;
	add.s64 	%rd25, %rd25, 4;
	add.s32 	%r32, %r32, 2;
	add.s32 	%r33, %r33, -1;
	setp.ne.s32 	%p6, %r33, 0;
	@%p6 bra 	$L__BB2_7;

$L__BB2_8:
	cvta.to.global.u64 	%rd22, %rd6;
	mul.wide.u32 	%rd23, %r1, 4;
	add.s64 	%rd24, %rd22, %rd23;
	st.global.f32 	[%rd24], %f29;

$L__BB2_9:
	ret;

}

